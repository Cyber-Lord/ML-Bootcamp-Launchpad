{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of my favorite resources on transfer learning:\n",
    "- [Fine-tuning with Keras and Deep Learning](https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/)\n",
    "- [Hands-On Transfer Learning with Python](https://www.amazon.in/Hands-Transfer-Learning-Python-TensorFlow-ebook/dp/B07CB455BF)\n",
    "- [Applying Deep Transfer Learning for Natural Language Processing (NLP)](https://github.com/dipanjanS/deep_transfer_learning_nlp_dhs2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from wandb.keras import WandbCallback\n",
    "from utils import data_utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for better reproducibility\n",
    "tf.random.set_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/ML-Bootcamp-Launchpad\" target=\"_blank\">https://app.wandb.ai/sayakpaul/ML-Bootcamp-Launchpad</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/ML-Bootcamp-Launchpad/runs/ct694prq\" target=\"_blank\">https://app.wandb.ai/sayakpaul/ML-Bootcamp-Launchpad/runs/ct694prq</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/sayakpaul/ML-Bootcamp-Launchpad/runs/ct694prq"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize wandb\n",
    "wandb.init(\"ml-bootcamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this\n",
    "CLASSES = [b'daisy', b'dandelion', b'roses', b'sunflowers', b'tulips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the constants\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load up the tfrecord filenames\n",
    "tfr_pattern_train = \"train_tfr/*.tfrec\"\n",
    "train_filenames = tf.io.gfile.glob(tfr_pattern_train)\n",
    "tfr_pattern_test = \"test_tfr/*.tfrec\"\n",
    "test_filenames = tf.io.gfile.glob(tfr_pattern_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train and test dataset\n",
    "training_dataset, steps_per_epoch = data_utils.batch_dataset(train_filenames, BATCH_SIZE, True)\n",
    "validation_dataset, validation_steps = data_utils.batch_dataset(test_filenames, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a utility function to define our model\n",
    "def create_model(img_size=(224,224), num_class=5, train_base=True):\n",
    "    input_layer = Input(shape=(img_size[0],img_size[1],3))\n",
    "    base = VGG16(input_tensor=input_layer,\n",
    "                    include_top=False,\n",
    "                    weights=\"imagenet\")\n",
    "    base.trainable = train_base\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    preds = Dense(num_class, activation=\"softmax\")(x)\n",
    "    return Model(inputs=input_layer, outputs=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to go for _layerwise pre-training_ as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model, supply the loss scaled optimizer,\n",
    "# and compile it\n",
    "model = create_model()\n",
    "opt = Adam(learning_rate=1e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "97/97 [==============================] - 78s 800ms/step - loss: 1.5380 - accuracy: 0.3012 - val_loss: 1.1774 - val_accuracy: 0.4246\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 68s 699ms/step - loss: 0.9845 - accuracy: 0.6044 - val_loss: 0.5448 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 68s 703ms/step - loss: 0.6473 - accuracy: 0.7577 - val_loss: 0.3829 - val_accuracy: 0.8658\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 68s 699ms/step - loss: 0.5481 - accuracy: 0.8038 - val_loss: 0.4505 - val_accuracy: 0.8419\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 68s 703ms/step - loss: 0.3798 - accuracy: 0.8599 - val_loss: 0.2895 - val_accuracy: 0.8768\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 68s 697ms/step - loss: 0.3773 - accuracy: 0.8621 - val_loss: 0.4355 - val_accuracy: 0.8529\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 68s 699ms/step - loss: 0.3749 - accuracy: 0.8621 - val_loss: 0.2017 - val_accuracy: 0.9265\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 68s 700ms/step - loss: 0.2582 - accuracy: 0.9066 - val_loss: 0.1668 - val_accuracy: 0.9504\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 68s 698ms/step - loss: 0.2172 - accuracy: 0.9201 - val_loss: 0.1378 - val_accuracy: 0.9485\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 67s 696ms/step - loss: 0.2638 - accuracy: 0.9111 - val_loss: 0.2034 - val_accuracy: 0.9412\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 67s 695ms/step - loss: 0.2111 - accuracy: 0.9243 - val_loss: 0.1405 - val_accuracy: 0.9449\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 67s 692ms/step - loss: 0.2069 - accuracy: 0.9220 - val_loss: 0.1384 - val_accuracy: 0.9577\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 68s 706ms/step - loss: 0.1553 - accuracy: 0.9475 - val_loss: 0.0682 - val_accuracy: 0.9724\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 67s 693ms/step - loss: 0.1350 - accuracy: 0.9494 - val_loss: 0.0995 - val_accuracy: 0.9724\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 67s 693ms/step - loss: 0.1637 - accuracy: 0.9410 - val_loss: 0.1442 - val_accuracy: 0.9632\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 67s 693ms/step - loss: 0.1438 - accuracy: 0.9507 - val_loss: 0.0715 - val_accuracy: 0.9798\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 67s 696ms/step - loss: 0.1236 - accuracy: 0.9523 - val_loss: 0.0647 - val_accuracy: 0.9816\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 67s 692ms/step - loss: 0.1139 - accuracy: 0.9607 - val_loss: 0.0946 - val_accuracy: 0.9614\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 67s 694ms/step - loss: 0.0969 - accuracy: 0.9623 - val_loss: 0.0619 - val_accuracy: 0.9779\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 67s 693ms/step - loss: 0.0936 - accuracy: 0.9707 - val_loss: 0.0370 - val_accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start = time.time()\n",
    "model.fit_generator(training_dataset, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[WandbCallback(data_type=\"image\", labels=CLASSES)])\n",
    "wandb.log({\"training_time\": time.time() - start})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are wondering why training loss is higher than the validation loss [this article](https://www.pyimagesearch.com/2019/10/14/why-is-my-validation-loss-lower-than-my-training-loss/) is an excellent read. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
